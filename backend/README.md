# Hawker Opportunity Score - Backend API

Production-ready PostgreSQL + Prisma database layer for the SC2006 Hawker Opportunity Score platform.

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+ and npm
- PostgreSQL 15+
- Git

### Installation

```bash
# Install dependencies
npm install

# Set up environment variables
cp env.example .env
# Edit .env with your database credentials and configuration

# Generate Prisma client
npm run db:generate

# Run database migrations
npm run db:migrate

# Seed database with sample data
npm run db:seed

# Start development server
npm run dev
```

The API will be available at `http://localhost:3001`

## ğŸ“Š Database Setup

### Initial Setup

```bash
# Generate Prisma Client from schema
npm run db:generate

# Run migrations (production)
npm run db:migrate

# Run migrations (development with prompts)
npm run db:migrate:dev

# Seed with 5 sample subzones
npm run db:seed

# Reset database (WARNING: deletes all data)
npm run db:reset
```

### Database Schema

The system uses PostgreSQL with Prisma ORM. Core models:

- **Subzone**: Singapore URA subzones with stable IDs, names, regions, and optional GeoJSON
- **Population**: Latest population data per subzone (1:1 relationship)
- **PopulationUnmatched**: Logs entries from government datasets that couldn't be matched
- **DatasetSnapshot**: Audit trail of data ingestion runs with status and metadata

See `/docs/DATA_SOURCES.md` for detailed schema documentation.

## ğŸ”„ Data Ingestion

### Population Data Ingestion

```bash
# Run population data ingestion
npm run ingest:population
```

**Features**:
- âœ… Fetches from government open data portal (when URL configured)
- âœ… Normalizes and matches subzone names
- âœ… Records unmatched entries for review
- âœ… Idempotent (safe to run multiple times)
- âœ… Creates audit snapshots
- âœ… Gracefully handles missing/unavailable data sources

**Configuration**:

Set `GOV_POPULATION_DATA_URL` in `.env`:
```bash
GOV_POPULATION_DATA_URL=https://data.gov.sg/api/...
```

**Without Data Source**:
If URL is not configured, the script will:
- Log a warning (not an error)
- Use existing seed data
- Create a snapshot with `partial` status
- Allow the system to continue functioning

### Viewing Ingestion Results

```sql
-- Latest snapshot
SELECT * FROM "DatasetSnapshot"
WHERE kind = 'population'
ORDER BY "startedAt" DESC
LIMIT 1;

-- Unmatched entries
SELECT "sourceKey", "rawName", "reason"
FROM "PopulationUnmatched"
ORDER BY "createdAt" DESC;

-- Population data
SELECT s.name, p.total, p.year
FROM "Subzone" s
LEFT JOIN "Population" p ON s.id = p."subzoneId";
```

## ğŸ§ª Testing

```bash
# Run all tests
npm test

# Run tests in watch mode
npm run test:watch
```

**Test Coverage**:
- âœ… Name normalization (case, punctuation, spacing)
- âœ… Matching algorithms (exact, alias)
- âœ… Upsert idempotency
- âœ… Snapshot creation
- âœ… Unmatched entry logging

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ prisma/
â”‚   â”œâ”€â”€ schema.prisma           # Database schema
â”‚   â”œâ”€â”€ seed.ts                 # Sample data
â”‚   â””â”€â”€ migrations/             # Database migrations
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.ts                 # Server entry point
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â””â”€â”€ index.ts           # Prisma client singleton
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ ingest/
â”‚   â”‚       â”œâ”€â”€ population.ts   # Main ingestion logic
â”‚   â”‚       â”œâ”€â”€ utils/
â”‚   â”‚       â”‚   â”œâ”€â”€ normalize.ts    # Name normalization
â”‚   â”‚       â”‚   â””â”€â”€ geo-matcher.ts  # Subzone matching
â”‚   â”‚       â””â”€â”€ __tests__/
â”‚   â”‚           â””â”€â”€ population.ingest.spec.ts
â”‚   â”œâ”€â”€ controllers/            # API route handlers
â”‚   â”œâ”€â”€ routers/                # Express routers
â”‚   â”œâ”€â”€ middlewares/            # Auth, error handling
â”‚   â””â”€â”€ schemas/                # Zod validation schemas
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ DATA_SOURCES.md        # Data dictionary
â”œâ”€â”€ env.example                 # Environment template
â”œâ”€â”€ package.json
â””â”€â”€ README.md                   # This file
```

## ğŸ”§ Available Scripts

| Script | Description |
|--------|-------------|
| `npm run dev` | Start development server with hot reload |
| `npm run build` | Build for production |
| `npm start` | Run production server |
| `npm run db:generate` | Generate Prisma Client |
| `npm run db:migrate` | Run migrations (production) |
| `npm run db:migrate:dev` | Run migrations (development) |
| `npm run db:reset` | Reset database (deletes all data) |
| `npm run db:seed` | Seed database with sample data |
| `npm run ingest:population` | Run population data ingestion |
| `npm test` | Run tests |
| `npm run test:watch` | Run tests in watch mode |

## ğŸŒ Environment Variables

Create a `.env` file based on `env.example`:

```bash
# Required
DATABASE_URL=postgresql://user:password@localhost:5432/dbname
JWT_SECRET=your-secret-key

# Optional
GOV_POPULATION_DATA_URL=https://data.gov.sg/...
PORT=3001
NODE_ENV=development
FRONTEND_URL=http://localhost:3000
```

## ğŸ“– API Endpoints

### Health Check
```
GET /health
```

### Authentication
```
POST /api/auth/register   # Register new user
POST /api/auth/login      # Login
GET  /api/auth/profile    # Get profile
```

### Subzones API v1 (Task 2)

#### List Subzones
```
GET /api/v1/subzones
```

**Query Parameters:**
- `region` (optional): Filter by region (CENTRAL, EAST, NORTH, NORTH_EAST, WEST, UNKNOWN)
- `ids` (optional): Comma-separated subzone IDs
- `q` (optional): Case-insensitive search query for name
- `limit` (optional): Max results (default: 200, max: 500)
- `offset` (optional): Skip N results (default: 0)

**Response:**
```json
[
  {
    "id": "TAMPINES_EAST",
    "name": "Tampines East",
    "region": "EAST",
    "population": {
      "total": 45000,
      "year": 2023
    },
    "info": {
      "missing": ["population"]  // Only present if data missing
    }
  }
]
```

#### Get Subzone Details
```
GET /api/v1/subzones/:id
```

**Response:**
```json
{
  "id": "TAMPINES_EAST",
  "name": "Tampines East",
  "region": "EAST",
  "population": {
    "total": 45000,
    "year": 2023
  },
  "metrics": {
    "demand": null,
    "supply": null,
    "accessibility": null,
    "score": null
  },
  "info": {
    "missing": ["metrics"]
  }
}
```

**Errors:**
- `404 NOT_FOUND` - Subzone does not exist

#### Batch Get Subzones
```
GET /api/v1/subzones:batch?ids=id1,id2,id3
```

**Query Parameters:**
- `ids` (required): Comma-separated IDs (2-8 values)

**Response:**
```json
{
  "data": [
    { /* SubzoneDetail */ },
    { /* SubzoneDetail */ }
  ],
  "notFound": ["NONEXISTENT_ID"]  // Only present if some IDs not found
}
```

**Errors:**
- `400 BAD_REQUEST` - Invalid IDs (less than 2 or more than 8)

#### Get GeoJSON for Map
```
GET /api/v1/geo/subzones
```

**Query Parameters:**
- `region` (optional): Filter by region

**Response:**
```json
{
  "type": "FeatureCollection",
  "features": [
    {
      "type": "Feature",
      "id": "TAMPINES_EAST",
      "properties": {
        "id": "TAMPINES_EAST",
        "name": "Tampines East",
        "region": "EAST",
        "populationTotal": 45000,
        "populationYear": 2023,
        "missing": ["population"]  // Only if data missing
      },
      "geometry": {
        "type": "Polygon",
        "coordinates": [[...]]
      }
    }
  ]
}
```

**Errors:**
- `503 GEODATA_UNAVAILABLE` - GeoJSON temporarily unavailable

#### Get Unmatched Population (Dev Only)
```
GET /api/v1/population/unmatched
```

**Query Parameters:**
- `limit` (optional): Max results (default: 100)
- `offset` (optional): Skip N results (default: 0)

**Response:**
```json
{
  "items": [
    {
      "id": "...",
      "sourceKey": "...",
      "rawName": "...",
      "reason": "no_match",
      "details": {...},
      "createdAt": "..."
    }
  ],
  "total": 10,
  "limit": 100,
  "offset": 0
}
```

**Errors:**
- `403 FORBIDDEN` - Only available in development mode

### Legacy Endpoints
```
GET  /api/subzones              # List all subzones (legacy)
GET  /api/subzones/:id          # Get subzone details (legacy)
GET  /api/subzones/search?q=... # Search by name (legacy)
```

### Admin
```
POST /api/admin/refresh-datasets  # Trigger data refresh
GET  /api/admin/snapshots         # List snapshots
```

### Notes on Missing Data

All endpoints gracefully handle missing population data:
- `population` is `null` when unavailable
- `info.missing` array indicates what data is missing
- HTTP 200 responses are still returned (non-blocking)
- Clients should check for `missing` flags and display "â€”" or "No data"

### GeoJSON Fallback

If subzones don't have `geomGeoJSON` in the database, the API loads from:
```
/backend/public/data/subzones.geojson
```

This file contains simple demo polygons matching the seed data. For production, populate the database with actual URA subzone geometries.

## ğŸ”’ Security

- JWT-based authentication
- Password hashing with bcrypt
- Input validation with Zod
- SQL injection protection via Prisma
- CORS configuration
- Helmet.js for HTTP headers

## ğŸ“Š Database Maintenance

### Adding New Subzones

```typescript
await prisma.subzone.create({
  data: {
    id: 'SUBZONE_ID',
    name: 'Subzone Name',
    region: 'EAST', // CENTRAL, EAST, NORTH, NORTH_EAST, WEST, UNKNOWN
  },
});
```

### Adding Aliases

Edit `/src/services/ingest/utils/geo-matcher.ts`:

```typescript
export const ALIASES: Record<string, string> = {
  "ALTERNATE_NAME": "SUBZONE_ID",
};
```

Then re-run ingestion:
```bash
npm run ingest:population
```

## ğŸ› Troubleshooting

### Database Connection Issues

```bash
# Check PostgreSQL is running
psql -U postgres -c "SELECT version();"

# Verify DATABASE_URL in .env
echo $DATABASE_URL

# Test connection
npm run db:generate
```

### Migration Errors

```bash
# Reset and start fresh (WARNING: deletes data)
npm run db:reset

# Or manually fix
npx prisma migrate resolve --applied <migration-name>
```

### High Unmatched Count

1. Check `/docs/DATA_SOURCES.md` for normalization rules
2. Add aliases in `/src/services/ingest/utils/geo-matcher.ts`
3. Re-run ingestion

## ğŸ“ Documentation

- [Data Sources & Schema](/docs/DATA_SOURCES.md) - Detailed data dictionary
- [Prisma Schema](/prisma/schema.prisma) - Database models
- [Ingestion Service](/src/services/ingest/population.ts) - Pipeline logic

## ğŸ¤ Contributing

1. Create feature branch
2. Make changes
3. Run tests: `npm test`
4. Build: `npm run build`
5. Commit and push

## ğŸ“„ License

MIT - SC2006 Team 5

## âœ… Task 1 Completion Checklist

- [x] Prisma schema with Subzone, Population, PopulationUnmatched, DatasetSnapshot
- [x] Migration `init_subzones_population_001` created and applied
- [x] Seed data with 5 sample subzones and population totals
- [x] Database client (`/src/db/index.ts`)
- [x] Normalization utilities (`/src/services/ingest/utils/normalize.ts`)
- [x] Geo-matcher with alias support (`/src/services/ingest/utils/geo-matcher.ts`)
- [x] Population ingestion service (`/src/services/ingest/population.ts`)
- [x] Comprehensive tests (`/src/services/ingest/__tests__/population.ingest.spec.ts`)
- [x] Data dictionary (`/docs/DATA_SOURCES.md`)
- [x] NPM scripts (db:generate, db:migrate, ingest:population, test)
- [x] `.env.example` with DATABASE_URL and GOV_POPULATION_DATA_URL
- [x] Graceful handling of missing/unavailable data sources
- [x] Idempotent ingestion (safe to re-run)
- [x] Unmatched entry logging
- [x] Dataset snapshots with audit trail

---

**Built with** â¤ï¸ **by SC2006 Team 5**

